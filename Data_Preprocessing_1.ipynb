{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.cluster import KMeans \n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from keybert import KeyBERT\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU_NUM = 1# 원하는 GPU 번호 입력\n",
    "# device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "# torch.cuda.set_device(device) # change allocation of current GPU\n",
    "# print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "# # Additional Infos\n",
    "# if device.type == 'cuda':\n",
    "#     print(torch.cuda.get_device_name(GPU_NUM))\n",
    "#     print('Memory Usage:')\n",
    "#     print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "#     print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#functions and models for clustering\n",
    "\n",
    "def revise_word(a):\n",
    "    if \"www\" in a:\n",
    "        return None\n",
    "    return a.replace(\"'s\",\"\").rstrip()\n",
    "\n",
    "class BoW():\n",
    "    def __init__(self):\n",
    "        self.dic = {}\n",
    "        self.size = 0\n",
    "\n",
    "    def add_dic(self,words):\n",
    "        for word in words:\n",
    "            word = revise_word(word)\n",
    "            if word in self.dic or word is None:\n",
    "                pass\n",
    "            else:\n",
    "                self.dic[word] = self.size\n",
    "                self.size = self.size + 1\n",
    "\n",
    "    def make_vec(self,words):\n",
    "        shape = (self.size,)\n",
    "        zeros_tensors = torch.zeros(shape, dtype=torch.float64)\n",
    "        for word in words:\n",
    "            word = revise_word(word)\n",
    "            if word in self.dic:\n",
    "                with torch.no_grad():\n",
    "                    zeros_tensors[self.dic[word]] = zeros_tensors[self.dic[word]] + 1\n",
    "            elif word is None:\n",
    "                pass\n",
    "            else:\n",
    "                raise Exception(\"No data in dictionary\")\n",
    "        return zeros_tensors\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "#make vector encoding for clustering\n",
    "def make_vector(fp):\n",
    "    bow = BoW()\n",
    "    data = pd.read_csv(fp)\n",
    "    dumps = data[:]['ne']\n",
    "    dic = []\n",
    "    for d in dumps:\n",
    "        d = ast.literal_eval(d)\n",
    "        bow.add_dic(d[0])\n",
    "    vectors = []\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        a = data.iloc[i]\n",
    "\n",
    "        ne = ast.literal_eval(a[\"ne\"])\n",
    "        ne_outputs = bow.make_vec(ne)\n",
    "\n",
    "\n",
    "        key = a[\"keyword\"]\n",
    "        inputs = tokenizer(key, return_tensors='pt')\n",
    "        key_outputs = model(**inputs).last_hidden_state[0][0]\n",
    "        with torch.no_grad():\n",
    "            vector = torch.cat((ne_outputs,key_outputs),0) \n",
    "        vectors.append(vector)\n",
    "    \n",
    "    data['vector'] = [v.detach().numpy() for v in vectors]\n",
    "\n",
    "    return data,vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-19 01:16:40.852222\n",
      "koreaherald_2017.csv\n",
      "                                                  title  author  \\\n",
      "0     People's Party members support Ahn's push for ...  Yonhap   \n",
      "1     [Newsmaker] Panamanian vessel probed over susp...  Yonhap   \n",
      "2     Hong Kong ship crew questioned in S. Korea for...     AFP   \n",
      "3     Additional bird flu case confirmed at duck far...  Yonhap   \n",
      "4                        Seoul issues fine dust warning  Yonhap   \n",
      "...                                                 ...     ...   \n",
      "9121        NK leader set to deliver New Year's address     임정요   \n",
      "9122  S. Korea's Marine Corps to deploy new guided m...     임정요   \n",
      "9123  Defense chief stresses new year poses new chal...     임정요   \n",
      "9124  N. Korea kicks off 2017 with large-scale firew...     임정요   \n",
      "9125  Acting president stresses security of country ...     임정요   \n",
      "\n",
      "                     time                                        description  \\\n",
      "0     2017-12-31 16:18:00  The leader of the center-left People's Party g...   \n",
      "1     2017-12-31 14:55:00  PYEONGTAEK  -- South Korea has seized and insp...   \n",
      "2     2017-12-30 15:44:00  The crew of a Hong Kong-registered ship have b...   \n",
      "3     2017-12-30 14:07:00  South Korea has confirmed a fresh case of avia...   \n",
      "4     2017-12-30 13:55:00  A fine dust warning was issued in Seoul for a ...   \n",
      "...                   ...                                                ...   \n",
      "9121  2017-01-01 09:38:00  North Korean leader Kim Jong-un is set to deli...   \n",
      "9122  2017-01-01 09:33:00  South Korea's Marine Corps will get new guided...   \n",
      "9123  2017-01-01 09:31:00  South Korea's defense chief stressed Sunday th...   \n",
      "9124  2017-01-01 09:30:00  North Korea kicked off the new year with a lar...   \n",
      "9125  2017-01-01 09:29:00  South Korea's acting President and Prime Minis...   \n",
      "\n",
      "                                                   body         section  \\\n",
      "0     The leader of the center-left People's Party g...        Politics   \n",
      "1     PYEONGTAEK  -- South Korea has seized and insp...     North Korea   \n",
      "2     The crew of a Hong Kong-registered ship have b...     North Korea   \n",
      "3     South Korea has confirmed a fresh case of avia...  Social affairs   \n",
      "4     A fine dust warning was issued in Seoul for a ...  Social affairs   \n",
      "...                                                 ...             ...   \n",
      "9121  North Korean leader Kim Jong-un is set to deli...     North Korea   \n",
      "9122  South Korea's Marine Corps will get new guided...         Defense   \n",
      "9123  South Korea's defense chief stressed Sunday th...         Defense   \n",
      "9124  North Korea kicked off the new year with a lar...     North Korea   \n",
      "9125  South Korea's acting President and Prime Minis...         Defense   \n",
      "\n",
      "      month  year  \n",
      "0        12  2017  \n",
      "1        12  2017  \n",
      "2        12  2017  \n",
      "3        12  2017  \n",
      "4        12  2017  \n",
      "...     ...   ...  \n",
      "9121      1  2017  \n",
      "9122      1  2017  \n",
      "9123      1  2017  \n",
      "9124      1  2017  \n",
      "9125      1  2017  \n",
      "\n",
      "[8658 rows x 8 columns]\n",
      "2021-06-19 01:17:25.488225\n",
      "100\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (101) does not match length of index (100)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-75f37ebefc2b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ne'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3038\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3039\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3040\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3114\u001b[0m         \"\"\"\n\u001b[1;32m   3115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3116\u001b[0;31m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3117\u001b[0m         \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_sanitize_column\u001b[0;34m(self, key, value, broadcast)\u001b[0m\n\u001b[1;32m   3762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m             \u001b[0;31m# turn me into an ndarray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3764\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msanitize_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3765\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3766\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36msanitize_index\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    745\u001b[0m     \"\"\"\n\u001b[1;32m    746\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 747\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    748\u001b[0m             \u001b[0;34m\"Length of values \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0;34mf\"({len(data)}) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (101) does not match length of index (100)"
     ]
    }
   ],
   "source": [
    "\n",
    "# match left and right single quotes\n",
    "single_quote_expr = re.compile(r'[\\u2018\\u2019]', re.U)\n",
    "# match all non-basic latin unicode\n",
    "unicode_chars_expr = re.compile(r'[\\u0080-\\uffff]', re.U)\n",
    "ne_type = ['ORG','GPE','PERSON','NORP']\n",
    "\n",
    "def cleanse_unicode(s):\n",
    "    if not s:\n",
    "        return \"\"\n",
    "\n",
    "    temp = single_quote_expr.sub(\"'\", s, re.U)\n",
    "    temp = unicode_chars_expr.sub(\"\", temp, re.U)\n",
    "    return temp\n",
    "\n",
    "class data():\n",
    "    def __init__(self, pt):\n",
    "        self.path = pt\n",
    "        self.file_list = os.listdir(pt)\n",
    "\n",
    "#add \"ne\" and \"keyword\" to data file\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "print(now)\n",
    "data_path = os.getcwd() + \"/data\"\n",
    "Data = data(data_path)\n",
    "kw_model = KeyBERT('distilbert-base-nli-mean-tokens')\n",
    "sp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for fp in os.listdir(data_path):\n",
    "    print(fp)\n",
    "    if fp != '.ipynb_checkpoints':\n",
    "        bow = BoW()\n",
    "        with open(data_path + \"/\" + fp, \"r\") as f:\n",
    "            df = pd.read_csv(f)\n",
    "\n",
    "        df = df[['title', 'author', 'time', 'description', 'body', 'section','month','year']].dropna()\n",
    "        print(df)\n",
    "\n",
    "        keywords = []\n",
    "        nes = []\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            a = df.iloc[i]\n",
    "            temp_s = a['title'] + \". \" + a['description']\n",
    "\n",
    "            keyword = kw_model.extract_keywords(temp_s, keyphrase_ngram_range=(1,4), stop_words=None, use_mmr=True, diversity=0.1)\n",
    "            keyword = \" ,\".join([word[0] for word in keyword])\n",
    "\n",
    "            keywords.append(keyword)\n",
    "\n",
    "            ne = [sp(a['description'])]\n",
    "            ne = [(e.text, e.lemma_, e.label_) for entities in ne for e in entities.ents]\n",
    "            ne = [n[1] for n in ne if n[2] in ne_type]\n",
    "            nes.append(ne)\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                now = datetime.datetime.now()\n",
    "                print(now)\n",
    "                print(i)\n",
    "        df['keyword'] = keywords\n",
    "        df['ne'] = nes\n",
    "        \n",
    "        for d in nes:\n",
    "            bow.add_dic(d[0])\n",
    "        vectors = []\n",
    "        \n",
    "        for i in range(len(nes)):\n",
    "            ne = nes[i]\n",
    "            key = keywords[i]\n",
    "            ne_outputs = bow.make_vec(ne)\n",
    "            inputs = tokenizer(key, return_tensors='pt')\n",
    "            key_outputs = model(**inputs).last_hidden_state[0][0]\n",
    "            with torch.no_grad():\n",
    "                vector = torch.cat((ne_outputs,key_outputs),0) \n",
    "            vectors.append(vector)\n",
    "        df['vector'] = vectors\n",
    "        vectors = [v.detach().numpy() for v in vectors]\n",
    "        kmeans = KMeans(n_clusters=20)\n",
    "        kmeans.fit(vectors)\n",
    "        df['cluster'] = kmeans.labels_\n",
    "        \n",
    "        data.to_csv(data_path + fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
