{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "from keybert import KeyBERT\n",
    "import spacy\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current cuda device  1\n",
      "GeForce RTX 2070 SUPER\n",
      "Memory Usage:\n",
      "Allocated: 0.0 GB\n",
      "Cached:    0.0 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tjrals/anaconda3/envs/cs474/lib/python3.7/site-packages/torch/cuda/__init__.py:104: UserWarning: \n",
      "GeForce RTX 3090 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_70.\n",
      "If you want to use the GeForce RTX 3090 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "GPU_NUM = 1# 원하는 GPU 번호 입력\n",
    "device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.set_device(device) # change allocation of current GPU\n",
    "print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "# Additional Infos\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(GPU_NUM))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(GPU_NUM)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_cached(GPU_NUM)/1024**3,1), 'GB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#functions and models for clustering\n",
    "\n",
    "def revise_word(a):\n",
    "    if \"www\" in a:\n",
    "        return None\n",
    "    return a.replace(\"'s\",\"\").rstrip()\n",
    "\n",
    "class BoW():\n",
    "    def __init__(self):\n",
    "        self.dic = {}\n",
    "        self.size = 0\n",
    "\n",
    "    def add_dic(self,words):\n",
    "        for word in words:\n",
    "            word = revise_word(word)\n",
    "            if word in self.dic or word is None:\n",
    "                pass\n",
    "            else:\n",
    "                self.dic[word] = self.size\n",
    "                self.size = self.size + 1\n",
    "\n",
    "    def make_vec(self,words):\n",
    "        shape = (self.size,)\n",
    "        zeros_tensors = torch.zeros(shape, dtype=torch.float64)\n",
    "        for word in words:\n",
    "            word = revise_word(word)\n",
    "            if word in self.dic:\n",
    "                with torch.no_grad():\n",
    "                    zeros_tensors[self.dic[word]] = zeros_tensors[self.dic[word]] + 1\n",
    "            elif word is None:\n",
    "                pass\n",
    "            else:\n",
    "                raise Exception(\"No data in dictionary\")\n",
    "        return zeros_tensors\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "year = [2015,2016,2017]\n",
    "\n",
    "for y in year:\n",
    "    data,vectors = make_vector('koreaherald_{}_30_ver_1.csv'.format(y))\n",
    "    \n",
    "    vectors = [v.detach().numpy() for v in vectors]\n",
    "    kmeans = KMeans(n_clusters=30)\n",
    "    kmeans.fit(vectors)\n",
    "    print(kmeans.labels_)\n",
    "    \n",
    "    data['cluster'] = kmeans.labels_\n",
    "    data.to_csv(\"koreaherald_{}\".format(y) +\"_30_ver_2.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "year:   0%|          | 0/3 [00:00<?, ?it/s]\n",
      "cluster:   0%|          | 0/13 [00:00<?, ?it/s]\u001b[A\n",
      "cluster:   8%|▊         | 1/13 [00:00<00:01,  6.60it/s]\u001b[A\n",
      "cluster: 100%|██████████| 13/13 [00:00<00:00, 37.26it/s][A\n",
      "year:  33%|███▎      | 1/3 [00:00<00:01,  1.86it/s]\n",
      "cluster:   0%|          | 0/18 [00:00<?, ?it/s]\u001b[A\n",
      "cluster:   6%|▌         | 1/18 [00:00<00:01,  9.77it/s]\u001b[A\n",
      "cluster:  44%|████▍     | 8/18 [00:00<00:00, 41.32it/s]\u001b[A\n",
      "cluster: 100%|██████████| 18/18 [00:00<00:00, 56.15it/s]\u001b[A\n",
      "year:  67%|██████▋   | 2/3 [00:01<00:00,  1.95it/s]\n",
      "cluster:   0%|          | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      "cluster:  20%|██        | 3/15 [00:00<00:00, 18.96it/s]\u001b[A\n",
      "cluster: 100%|██████████| 15/15 [00:00<00:00, 40.39it/s][A\n",
      "year: 100%|██████████| 3/3 [00:01<00:00,  1.86it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data_path = os.getcwd() + '/data'\n",
    "data_path_30 = os.getcwd() + \"/data/sub_cluster\"\n",
    "for y in tqdm(year, desc= 'year'):\n",
    "    fp = data_path + '/koreaherald_{}.csv'.format(y)\n",
    "    with open(fp, \"r\") as f:\n",
    "        df = pd.read_csv(f)\n",
    "    df = df[['title', 'description', 'body','keyword','ne','cluster','vector','author','section','month','year']].dropna()\n",
    "    cluster = df[:]['cluster']\n",
    "    for i in tqdm(set(cluster.tolist()),desc='cluster'):\n",
    "        d = df[df.cluster == i][:]\n",
    "        d.to_csv(data_path_30+\"/{}\".format(y)+'/korea_herald_c_{}.csv'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korea_herald_c_0.csv\n",
      "2021-06-08 22:47:23.822126\n",
      "0\n",
      "2021-06-08 22:47:55.778554\n",
      "100\n",
      "2021-06-08 22:48:32.135413\n",
      "200\n",
      "2021-06-08 22:49:09.158398\n",
      "300\n",
      "2021-06-08 22:49:47.746098\n",
      "400\n",
      "2021-06-08 22:50:24.344144\n",
      "500\n",
      "2021-06-08 22:51:03.374763\n",
      "600\n",
      "2021-06-08 22:51:40.183689\n",
      "700\n",
      "2021-06-08 22:52:16.306163\n",
      "800\n",
      "2021-06-08 22:52:54.219243\n",
      "900\n",
      "2021-06-08 22:53:32.670643\n",
      "1000\n",
      "2021-06-08 22:54:11.292297\n",
      "1100\n",
      "2021-06-08 22:54:48.206920\n",
      "1200\n",
      "2021-06-08 22:55:28.664107\n",
      "1300\n",
      "2021-06-08 22:56:05.993895\n",
      "1400\n",
      "2021-06-08 22:56:41.986362\n",
      "1500\n",
      "2021-06-08 22:57:20.229565\n",
      "1600\n",
      "2021-06-08 22:57:54.823927\n",
      "1700\n",
      "2021-06-08 22:58:29.632862\n",
      "1800\n",
      "2021-06-08 22:59:07.565628\n",
      "1900\n",
      "2021-06-08 22:59:43.936230\n",
      "2000\n",
      "2021-06-08 23:00:21.986753\n",
      "2100\n",
      "2021-06-08 23:00:59.789174\n",
      "2200\n",
      "2021-06-08 23:01:40.528509\n",
      "2300\n",
      "2021-06-08 23:02:20.542356\n",
      "2400\n",
      "2021-06-08 23:03:00.228203\n",
      "2500\n",
      "2021-06-08 23:03:37.170879\n",
      "2600\n",
      "                                                  title  \\\n",
      "0                     Inter-Korean ties face rocky road   \n",
      "1            Korean IMO chief to take office next month   \n",
      "2     Kim Jong-un offers condolences to his key aide...   \n",
      "3     Trump again accuses South Korea of getting def...   \n",
      "4                        City to toll bell for New Year   \n",
      "...                                                 ...   \n",
      "2682  N. Korean leader's speech arouses cautious opt...   \n",
      "2683  N. Korean leader open to inter-Korean summit t...   \n",
      "2684  Ex-U.S. envoy calls for clearer communication ...   \n",
      "2685           U.S. imposes sanctions on N. Korean firm   \n",
      "2686  Park calls for military readiness amid tension...   \n",
      "\n",
      "                                            description  \\\n",
      "0     Relations between the two Koreas are expected ...   \n",
      "1     The newly elected chief of the United Nations ...   \n",
      "2     North Korea's leader Kim Jong-un has offered \"...   \n",
      "3     Republican presidential front-runner Donald Tr...   \n",
      "4     Seoul City will mark the New Year with a bell-...   \n",
      "...                                                 ...   \n",
      "2682  North Korean leader Kim Jong-un's New Year's D...   \n",
      "2683  North Korean leader Kim Jong-un said Thursday ...   \n",
      "2684  The United States should make its thoughts on ...   \n",
      "2685  The United States has imposed sanctions on a N...   \n",
      "2686  President Park Geun-hye called on the military...   \n",
      "\n",
      "                                                   body  \\\n",
      "0     Relations between the two Koreas are expected ...   \n",
      "1     The newly elected chief of the United Nations ...   \n",
      "2     North Korea's leader Kim Jong-un has offered \"...   \n",
      "3     Republican presidential front-runner Donald Tr...   \n",
      "4     Seoul City will mark the New Year with a bell-...   \n",
      "...                                                 ...   \n",
      "2682  North Korean leader Kim Jong-un's New Year's D...   \n",
      "2683  North Korean leader Kim Jong-un said Thursday ...   \n",
      "2684  The United States should make its thoughts on ...   \n",
      "2685  The United States has imposed sanctions on a N...   \n",
      "2686  President Park Geun-hye called on the military...   \n",
      "\n",
      "                                                keyword  \\\n",
      "0     stalled tours to north ,frosty since their fir...   \n",
      "1     elected in june ,take office next month ,korea...   \n",
      "2     korea held state funeral ,tuesday in car accid...   \n",
      "3     front runner donald trump ,runner donald trump...   \n",
      "4     for new year seoul ,said seoul mayor park ,new...   \n",
      "...                                                 ...   \n",
      "2682  korean president park geun ,south korean presi...   \n",
      "2683  korean president park geun ,korean summit talk...   \n",
      "2684  nuclear negotiator said wednesday ,order to wi...   \n",
      "2685  sanctions on north korean ,sanctions on korean...   \n",
      "2686  war on the korean ,president park geun hye ,th...   \n",
      "\n",
      "                                                     ne  cluster  \\\n",
      "0                            ['Koreas', 'north korean']        0   \n",
      "1     ['the United Nations', 'south korean', 'Lim Ki...        0   \n",
      "2     [\"North Korea 's\", 'Kim Jong - un', 'inter - k...        0   \n",
      "3     ['republican', 'Donald Trump', 'South Korea', ...        0   \n",
      "4     ['Seoul City', 'the Seoul Metropolitan Governm...        0   \n",
      "...                                                 ...      ...   \n",
      "2682  ['north korean', \"Kim Jong - un 's\", 'Kim', 's...        0   \n",
      "2683  ['north korean', 'Kim Jong - un', 'south korea...        0   \n",
      "2684  ['the United States', 'North Korea', 'China', ...        0   \n",
      "2685  ['the United States', 'north korean', 'China',...        0   \n",
      "2686                       ['Park Geun', 'North Korea']        0   \n",
      "\n",
      "                                                 vector          author  \\\n",
      "0     [ 0.          0.          0.         ... -0.08...    Korea Herald   \n",
      "1     [ 1.          0.          0.         ... -0.48...          KH디지털2   \n",
      "2     [ 0.          0.          0.         ... -0.37...          KH디지털2   \n",
      "3     [ 3.          0.          0.         ... -0.66...          KH디지털2   \n",
      "4     [ 0.          0.          0.         ... -0.35...  Lee Hyun-jeong   \n",
      "...                                                 ...             ...   \n",
      "2682  [ 0.          0.          0.         ... -0.37...          KH디지털2   \n",
      "2683  [ 0.          0.          0.         ... -0.22...          KH디지털2   \n",
      "2684  [ 0.          1.          0.         ... -0.75...          KH디지털2   \n",
      "2685  [ 0.          1.          0.         ... -0.55...          KH디지털2   \n",
      "2686  [ 0.          0.          0.         ... -0.23...          KH디지털2   \n",
      "\n",
      "             section  month  year  \\\n",
      "0        North Korea     12  2015   \n",
      "1      International     12  2015   \n",
      "2        North Korea     12  2015   \n",
      "3            Defense     12  2015   \n",
      "4     Social affairs     12  2015   \n",
      "...              ...    ...   ...   \n",
      "2682     North Korea      1  2015   \n",
      "2683     North Korea      1  2015   \n",
      "2684     North Korea      1  2015   \n",
      "2685     North Korea      1  2015   \n",
      "2686         Defense      1  2015   \n",
      "\n",
      "                                              keyword_e  \\\n",
      "0     stalled tours to north korean ,months long fre...   \n",
      "1     operator was elected in june ,june to head the...   \n",
      "2     korea who died on tuesday ,north korea held st...   \n",
      "3     good trump said the billionaire ,presidential ...   \n",
      "4     firecrackers firecracker accidents have annual...   \n",
      "...                                                 ...   \n",
      "2682  south korean president park geun ,korean summi...   \n",
      "2683  south korean president park geun ,third new ye...   \n",
      "2684  reengagement with china north korea ,nuclear p...   \n",
      "2685  sanctions on north korean firm ,nation exports...   \n",
      "2686  with north korea killing five ,three days afte...   \n",
      "\n",
      "                                                   ne_e  \n",
      "0     [(Koreas, GPE), (north korean, NORP), (Dec.27,...  \n",
      "1     [(the United Nations, ORG), (south korean, NOR...  \n",
      "2     [(North Korea 's, GPE), (Kim Jong - un, PERSON...  \n",
      "3     [(republican, NORP), (Donald Trump, PERSON), (...  \n",
      "4     [(Seoul City, GPE), (the Seoul Metropolitan Go...  \n",
      "...                                                 ...  \n",
      "2682  [(north korean, NORP), (Kim Jong - un 's, PERS...  \n",
      "2683  [(north korean, NORP), (Kim Jong - un, PERSON)...  \n",
      "2684  [(the United States, GPE), (North Korea, GPE),...  \n",
      "2685  [(the United States, GPE), (north korean, NORP...  \n",
      "2686  [(Park Geun, PERSON), (North Korea, GPE), (Nor...  \n",
      "\n",
      "[2687 rows x 13 columns]\n",
      "2016.zip\n"
     ]
    },
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x95 in position 11: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-ac0935ab9ec3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m                 \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'description'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'body'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'keyword'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ne'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cluster'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'vector'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'author'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'section'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'month'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs474/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs474/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs474/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs474/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cs474/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x95 in position 11: invalid start byte"
     ]
    }
   ],
   "source": [
    "for y in year:\n",
    "    p = data_path_30 + '/{}'.format(y)\n",
    "    for fp in os.listdir(p):\n",
    "        print(fp)\n",
    "        if fp == '.ipynb_checkpoints':\n",
    "            pass\n",
    "        else:\n",
    "            with open(p +\"/\"+ fp) as f:\n",
    "                df = pd.read_csv(f)\n",
    "            df = df[['title', 'description', 'body','keyword','ne','cluster','vector','author','section','month','year']].dropna()\n",
    "\n",
    "            keywords = []\n",
    "            nes = []\n",
    "\n",
    "            for i in range(df.shape[0]):\n",
    "                a = df.iloc[i]\n",
    "                temp_s = a['body']\n",
    "\n",
    "                keyword = kw_model.extract_keywords(temp_s, keyphrase_ngram_range=(1,5), stop_words=None, use_mmr=True, diversity=0.1)\n",
    "                keyword = \" ,\".join([word[0] for word in keyword])\n",
    "\n",
    "                keywords.append(keyword)\n",
    "\n",
    "                ne = [sp(a['body'])]\n",
    "                ne = [(e.text, e.lemma_, e.label_) for entities in ne for e in entities.ents]\n",
    "                ne = [(n[1],n[2]) for n in ne if n[2] in ne_type]\n",
    "                nes.append(ne)\n",
    "\n",
    "                if i % 100 == 0:\n",
    "                    now = datetime.datetime.now()\n",
    "                    print(now)\n",
    "                    print(i)\n",
    "            df['keyword_e'] = keywords\n",
    "            df['ne_e'] = nes\n",
    "            print(df)\n",
    "            df.to_csv(p+\"/\"+fp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korea_herald_c_0.csv\n",
      "[ 8 17  3 ...  5 19  3]\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "for y in year:\n",
    "    p = data_path_30 + '/{}'.format(y)\n",
    "    for i in range(data.shape[0]):\n",
    "        a = data.iloc[i]\n",
    "\n",
    "        ne = ast.literal_eval(a[\"ne\"])\n",
    "        ne_outputs = bow.make_vec(ne)\n",
    "    for fp in os.listdir(p):\n",
    "        print(fp)\n",
    "        if fp == '.ipynb_checkpoints':\n",
    "            pass\n",
    "        else:\n",
    "            data,vectors = make_vector(p+ '/' + fp)\n",
    "\n",
    "            vectors = [v.detach().numpy() for v in vectors]\n",
    "            kmeans = KMeans(n_clusters=20)\n",
    "            kmeans.fit(vectors)\n",
    "            print(kmeans.labels_)\n",
    "\n",
    "            data['cluster_e'] = kmeans.labels_\n",
    " \n",
    "            data.to_csv(p + '/' + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "korea_herald_c_0.csv\n",
      "korea_herald_c_9.csv\n",
      "korea_herald_c_7.csv\n",
      "korea_herald_c_14.csv\n",
      "korea_herald_c_29.csv\n",
      "korea_herald_c_1.csv\n",
      "korea_herald_c_10.csv\n",
      "korea_herald_c_3.csv\n",
      "korea_herald_c_8.csv\n",
      "korea_herald_c_2.csv\n",
      "korea_herald_c_28.csv\n",
      "korea_herald_c_17.csv\n",
      "korea_herald_c_5.csv\n",
      "korea_herald_c_0.csv\n",
      "korea_herald_c_9.csv\n",
      "korea_herald_c_7.csv\n",
      "korea_herald_c_14.csv\n",
      "korea_herald_c_29.csv\n",
      "korea_herald_c_1.csv\n",
      "korea_herald_c_10.csv\n",
      "korea_herald_c_3.csv\n",
      "korea_herald_c_8.csv\n",
      "korea_herald_c_2.csv\n",
      "korea_herald_c_28.csv\n",
      "korea_herald_c_17.csv\n",
      "korea_herald_c_5.csv\n",
      "korea_herald_c_26.csv\n",
      "korea_herald_c_4.csv\n",
      "korea_herald_c_18.csv\n",
      "korea_herald_c_0.csv\n",
      "korea_herald_c_9.csv\n",
      "korea_herald_c_7.csv\n",
      "korea_herald_c_14.csv\n",
      "korea_herald_c_15.csv\n",
      "korea_herald_c_10.csv\n",
      "korea_herald_c_27.csv\n",
      "korea_herald_c_8.csv\n",
      "korea_herald_c_19.csv\n",
      "korea_herald_c_2.csv\n",
      "korea_herald_c_28.csv\n",
      "korea_herald_c_5.csv\n",
      "korea_herald_c_21.csv\n",
      "korea_herald_c_16.csv\n",
      "korea_herald_c_25.csv\n",
      "korea_herald_c_26.csv\n",
      "korea_herald_c_4.csv\n",
      "korea_herald_c_18.csv\n",
      "korea_herald_c_0.csv\n",
      "korea_herald_c_9.csv\n",
      "korea_herald_c_7.csv\n",
      "korea_herald_c_14.csv\n",
      "korea_herald_c_15.csv\n",
      "korea_herald_c_10.csv\n",
      "korea_herald_c_27.csv\n",
      "korea_herald_c_8.csv\n",
      "korea_herald_c_19.csv\n",
      "korea_herald_c_2.csv\n",
      "korea_herald_c_28.csv\n",
      "korea_herald_c_5.csv\n",
      "korea_herald_c_21.csv\n",
      "korea_herald_c_16.csv\n",
      "korea_herald_c_25.csv\n",
      "korea_herald_c_26.csv\n",
      "korea_herald_c_4.csv\n",
      "korea_herald_c_6.csv\n",
      "korea_herald_c_0.csv\n",
      "korea_herald_c_29.csv\n",
      "korea_herald_c_1.csv\n",
      "korea_herald_c_10.csv\n",
      "korea_herald_c_27.csv\n",
      "korea_herald_c_3.csv\n",
      "korea_herald_c_20.csv\n",
      "korea_herald_c_8.csv\n",
      "korea_herald_c_13.csv\n",
      "korea_herald_c_19.csv\n",
      "korea_herald_c_2.csv\n",
      "korea_herald_c_21.csv\n",
      "korea_herald_c_26.csv\n",
      "korea_herald_c_4.csv\n",
      "korea_herald_c_6.csv\n",
      "korea_herald_c_0.csv\n",
      "korea_herald_c_29.csv\n",
      "korea_herald_c_1.csv\n",
      "korea_herald_c_10.csv\n",
      "korea_herald_c_27.csv\n",
      "korea_herald_c_3.csv\n",
      "korea_herald_c_20.csv\n",
      "korea_herald_c_8.csv\n",
      "korea_herald_c_13.csv\n",
      "korea_herald_c_19.csv\n",
      "korea_herald_c_2.csv\n",
      "korea_herald_c_21.csv\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "for y in year:\n",
    "    p = data_path_30 + '/{}'.format(y)\n",
    "    bow = BoW()\n",
    "    for fp in os.listdir(p):\n",
    "        if 'csv' in fp:\n",
    "            print(fp)\n",
    "            with open(p +\"/\"+ fp) as f:\n",
    "                df = pd.read_csv(f)\n",
    "            df = df[['title', 'description', 'body','keyword','ne','cluster','vector','author','section','month','year','ne_e','keyword_e']].dropna()\n",
    "            dumps = df[:]['ne_e']\n",
    "            for d in dumps:\n",
    "                d = ast.literal_eval(d)\n",
    "                bow.add_dic(d)\n",
    "    for fp in os.listdir(p):\n",
    "        if 'csv' in fp:\n",
    "            print(fp)\n",
    "            vectors = []\n",
    "            with open(p +\"/\"+ fp) as f:\n",
    "                df = pd.read_csv(f)\n",
    "            df = df[['title', 'description', 'body','keyword','ne','cluster','vector','author','section','month','year','ne_e','keyword_e']].dropna()\n",
    "            for i in range(df.shape[0]):    \n",
    "                a = df.iloc[i]\n",
    "\n",
    "                ne = ast.literal_eval(a[\"ne_e\"])\n",
    "                ne_outputs = bow.make_vec(ne)\n",
    "\n",
    "\n",
    "                key = a[\"keyword\"]\n",
    "                inputs = tokenizer(key, return_tensors='pt')\n",
    "                key_outputs = model(**inputs).last_hidden_state[0][0]\n",
    "                with torch.no_grad():\n",
    "                    vector = torch.cat((ne_outputs,key_outputs),0) \n",
    "                vectors.append(vector)\n",
    "            fp = fp.replace('csv','txt')\n",
    "            with open(p+\"/\"+fp , 'wb') as lf:\n",
    "                pickle.dump(vectors, lf)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
